{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Issues\n",
    "# 1. VAE is trainable, but the loss doesn't get lower enough.. Thus, the reconstruction shows poor result. I will Paul about this issue\n",
    "# ... Solution 1) Use sub-pixel upsampling.\n",
    "# ... Solution 2) This might be a problem: https://distill.pub/2016/deconv-checkerboard/\n",
    "# ... Solution 3) Training more might will help\n",
    "# ... Solution 4) Rescale output image, since it is normalized at the input stage (not sure)\n",
    "\n",
    "# Idea\n",
    "# 1. Data augmentation would be helpful in terms of feeding variety dataset.\n",
    "# 2. We might want to try a stacked autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "# these ones let us draw images in our notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.python.framework import tensor_util\n",
    "import math\n",
    "\n",
    "#imports data\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# CIFAR 100 #\n",
    "#############\n",
    "\n",
    "cifar100_test = {}\n",
    "cifar100_train = {}\n",
    "# Load the raw CIFAR-100 data.\n",
    "cifar100_test = unpickle('dataset/cifar-100-python/test')\n",
    "cifar100_train = unpickle('dataset/cifar-100-python/train')\n",
    "\n",
    "train_data = cifar100_train[b'data']\n",
    "test_data = cifar100_test[b'data']\n",
    "\n",
    "train_data = np.reshape(train_data,(50000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "test_data = np.reshape(test_data,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "# CIFAR 10 #\n",
    "############\n",
    "\n",
    "cifar10_train = {}\n",
    "cifar10_test  = {}\n",
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_1')\n",
    "train_data_1 = cifar10_train[b'data']\n",
    "train_data_1 = np.reshape(train_data_1,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_2')\n",
    "train_data_2 = cifar10_train[b'data']\n",
    "train_data_2 = np.reshape(train_data_2,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_3')\n",
    "train_data_3 = cifar10_train[b'data']\n",
    "train_data_3 = np.reshape(train_data_3,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_4')\n",
    "train_data_4 = cifar10_train[b'data']\n",
    "train_data_4 = np.reshape(train_data_4,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_5')\n",
    "train_data_5 = cifar10_train[b'data']\n",
    "train_data_5 = np.reshape(train_data_5,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_test  = unpickle('dataset/cifar-10-python/test_batch')\n",
    "test_data  = cifar10_test[b'data']\n",
    "test_data = np.reshape(test_data,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "\n",
    "train_data = []\n",
    "train_data.append(train_data_1)\n",
    "train_data.append(train_data_2)\n",
    "train_data.append(train_data_3)\n",
    "train_data.append(train_data_4)\n",
    "train_data.append(train_data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# This will go to util.py #\n",
    "###########################\n",
    "\n",
    "# Normalization: Input image should be normalized to have 0 mean and unit variation for the VAE.\n",
    "train_data_normalized = train_data\n",
    "for i in range(5):\n",
    "    for j in range(10000):\n",
    "        train_data_normalized[i][j] = train_data[i][j]-np.mean(train_data[i][j])\n",
    "        train_data_normalized[i][j] = train_data_normalized[i][j]/np.std(train_data_normalized[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8503717077085941e-17"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_data_normalized[0][9])\n",
    "#train_data_normalized[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 115047\n",
      "0 th training batch...\n",
      "Total loss:  1.12137\n",
      "Total loss:  0.999505\n",
      "Total loss:  0.998327\n",
      "Total loss:  0.999002\n",
      "Total loss:  0.99895\n",
      "Total loss:  0.998102\n",
      "Total loss:  0.999796\n",
      "Total loss:  0.997393\n",
      "Total loss:  0.99755\n",
      "Total loss:  0.998372\n",
      "1 th training batch...\n",
      "Total loss:  0.997023\n",
      "Total loss:  0.998686\n",
      "Total loss:  0.99659\n",
      "Total loss:  0.999857\n",
      "Total loss:  0.997359\n",
      "Total loss:  0.996667\n",
      "Total loss:  0.998451\n",
      "Total loss:  0.997781\n",
      "Total loss:  0.997063\n",
      "Total loss:  1.00006\n",
      "2 th training batch...\n",
      "Total loss:  0.997341\n",
      "Total loss:  0.996388\n",
      "Total loss:  0.997841\n",
      "Total loss:  0.99734\n",
      "Total loss:  0.998688\n",
      "Total loss:  0.999073\n",
      "Total loss:  0.999902\n",
      "Total loss:  0.99759\n",
      "Total loss:  0.99946\n",
      "Total loss:  0.998511\n",
      "3 th training batch...\n",
      "Total loss:  0.998217\n",
      "Total loss:  0.998012\n",
      "Total loss:  0.998896\n",
      "Total loss:  0.996089\n",
      "Total loss:  0.994283\n",
      "Total loss:  0.994577\n",
      "Total loss:  0.996127\n",
      "Total loss:  0.993213\n",
      "Total loss:  0.998179\n",
      "Total loss:  0.997211\n",
      "4 th training batch...\n",
      "Total loss:  0.998001\n",
      "Total loss:  0.99436\n",
      "Total loss:  0.993726\n",
      "Total loss:  1.00028\n",
      "Total loss:  0.995985\n",
      "Total loss:  0.996702\n",
      "Total loss:  0.995823\n",
      "Total loss:  0.99585\n",
      "Total loss:  0.99571\n",
      "Total loss:  0.995889\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Simple Autoencoder #\n",
    "######################\n",
    "# This one is for playing around to figure how does AE work. It won't be our model.\n",
    "\n",
    "def upscale_block(x, f, scale=2):\n",
    "    \"\"\" conv2d_transpose \"\"\"\n",
    "    x = tf.layers.conv2d_transpose(x, f, 3, strides=(scale, scale), padding='same', activation=tf.nn.relu)\n",
    "    x = tf.nn.dropout(x, 0.5)\n",
    "    return x\n",
    "\n",
    "def downscale_block(x, f, scale=2):\n",
    "    n, h, w, c = x.get_shape().as_list()\n",
    "    conv = tf.layers.conv2d(x, f, 3, strides=1, padding='same')\n",
    "    pool = tf.layers.max_pooling2d(conv, pool_size=(2,2), strides=scale, padding='same')\n",
    "    return pool\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\" inputs must be in (0, 1) \"\"\"\n",
    "    return p * tf.log(p/q) + (1-p) * tf.log((1-p)/(1-q))\n",
    "\n",
    "def autoencoder_network(x, code_size=128):\n",
    "    encoder_16 = downscale_block(x, 8)\n",
    "    encoder_8 = downscale_block(encoder_16, 16)\n",
    "    encoder_4 = downscale_block(encoder_8, 32)\n",
    "    flatten_dim = np.prod(encoder_4.get_shape().as_list()[1:])\n",
    "    flat = tf.reshape(encoder_4, [-1, flatten_dim])\n",
    "    code = tf.layers.dense(flat, code_size, activation=tf.nn.relu)\n",
    "    hidden_decoder = tf.layers.dense(code, flatten_dim, activation=tf.nn.elu)\n",
    "    decoder_4 = tf.reshape(hidden_decoder, [-1,4,4,32])\n",
    "    decoder_8 = upscale_block(decoder_4, 16)\n",
    "    decoder_16 = upscale_block(decoder_8, 8)\n",
    "    output = upscale_block(decoder_16, 3)\n",
    "    return code, output\n",
    "\n",
    "# set hyperparameters\n",
    "sparsity_weight = 5e-3\n",
    "code_size = 100\n",
    "\n",
    "# define graph\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "code, outputs = autoencoder_network(x, code_size)\n",
    "\n",
    "# just for fun\n",
    "num_params = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "print('Parameters: ' + str(num_params))\n",
    "\n",
    "# calculate loss\n",
    "sparsity_loss = tf.norm(code, ord=1, axis=1)\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - x)) # MSE\n",
    "total_loss = reconstruction_loss + sparsity_weight * sparsity_loss\n",
    "\n",
    "# setup optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train_op = optimizer.minimize(total_loss)\n",
    "\n",
    "# train for an epoch and visualize\n",
    "batch_size = 100\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    # train batch (1 to 5)\n",
    "    for k in range(5):\n",
    "        print(k,\"th training batch...\")\n",
    "        for i in range(train_data[k].shape[0] // batch_size):\n",
    "            batch_xs = train_data[k][i*batch_size:(i+1)*batch_size, :]\n",
    "            _,tl = session.run([train_op, total_loss], {x: batch_xs})\n",
    "            if i%10 ==0:\n",
    "                print(\"Total loss: \", np.average(tl))\n",
    "print(\"Done!\")\n",
    "#### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nonzero code dimensions: 1/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee525179b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################\n",
    "# Simple Autoencoder #\n",
    "######################\n",
    "# Visualize result\n",
    "\n",
    "idx = np.random.randint(test_data.shape[0])\n",
    "x_out, code_out, output_out = session.run([x, code, outputs], {x: np.expand_dims(test_data[idx], axis=0)})\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(np.squeeze(x_out).astype(\"uint8\"))\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(np.squeeze(output_out).astype(\"uint8\"))\n",
    "\n",
    "#print(code_out)\n",
    "print(\"Number of nonzero code dimensions: {}/{}\".format(np.count_nonzero(code_out), code_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# model of VAE #\n",
    "################\n",
    "# This will go to model.py \n",
    "\n",
    "def lrelu(x, alpha=0.3):\n",
    "    return tf.maximum(x, tf.multiply(x, alpha))\n",
    "\n",
    "def conv_block(inputs, filters, downscale=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - inputs: 4D tensor of shape NHWC\n",
    "        - filters: int\n",
    "    \"\"\"\n",
    "    with tf.name_scope('conv_block') as scope:\n",
    "        conv = tf.layers.conv2d(inputs, filters, 2, 1, padding='same', activation=tf.nn.elu)\n",
    "        pool = tf.layers.max_pooling2d(conv, pool_size=(2,2), strides=downscale, padding='same')\n",
    "        return pool\n",
    "\n",
    "def gaussian_encoder(inputs, latent_size):\n",
    "    \"\"\"inputs should be a tensor of images whose height and width are multiples of 4\"\"\"\n",
    "    with tf.name_scope('downscale_1') as scope:\n",
    "        conv_16 = conv_block(inputs, 4, downscale=2)      # (?, 16, 16,  4)\n",
    "    with tf.name_scope('downscale_2') as scope:\n",
    "        conv_8 = conv_block(conv_16, 8, downscale=2)      # (?,  8,  8,  8)\n",
    "    with tf.name_scope('downscale_3') as scope:\n",
    "        conv_4 = conv_block(conv_8, 16, downscale=2)      # (?,  4,  4, 16)\n",
    "    conv_4_flat = tf.reshape(conv_4, [-1, 4*4*16])\n",
    "    \n",
    "    mean = tf.layers.dense(conv_4_flat, latent_size, name='mean')              # (?, 4*4*16)\n",
    "    log_scale = tf.layers.dense(conv_4_flat, latent_size, name='log_scale')    # (?, 4*4*16)\n",
    "    return mean, log_scale                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# model of VAE #\n",
    "################\n",
    "# This will go to model.py \n",
    "\n",
    "def upscale_block(x, f=1, scale=2, name='upscale_block'):\n",
    "    x = tf.layers.conv2d_transpose(x, f, 2, strides=(scale, scale), padding='same', activation=tf.nn.elu)\n",
    "    return x\n",
    "\n",
    "def decoder(codes, name):\n",
    "    hidden_decoder = tf.layers.dense(codes, 4*4*16) # (?,  4x4x8)\n",
    "#    hidden_decoder = tf.layers.dense(codes, 4*4*8) # (?,  4x4x8)\n",
    "    decoder_4 = tf.reshape(hidden_decoder, [-1, 4, 4, 16])           # (?,  4,  4, 16)\n",
    "    decoder_8 = upscale_block(decoder_4, 8, name='up_1')             # (?,  8,  8,  8)\n",
    "    decoder_16 = upscale_block(decoder_8, 4, name='up_2')            # (?, 16, 16,  4)\n",
    "    output = upscale_block(decoder_16, 3, name=name)                 # (?, 32, 32,  3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'div_1:0' shape=(32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.image.per_image_standardization(train_data[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Util of VAE #\n",
    "###############\n",
    "# This will go to util.py \n",
    "\n",
    "def gaussian_sample(mean, log_scale):\n",
    "    # noise inputsis zero centered and std. dev. 1\n",
    "    gaussian_noise = tf.random_normal(shape=tf.shape(mean)) # Sampling...\n",
    "    return mean + (tf.exp(log_scale) * gaussian_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(60, ?) dtype=float32>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.relu(tf.reshape(inputs, [60, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Util of VAE #\n",
    "###############\n",
    "# This will go to util.py \n",
    "\n",
    "# define an epsilon\n",
    "EPS = 1e-10\n",
    "\n",
    "def std_gaussian_KL_divergence(mu, log_sigma):\n",
    "    \"\"\"Analytic KL distance between N(mu, e^log_sigma) and N(0, 1)\"\"\"\n",
    "    sigma = tf.exp(log_sigma)\n",
    "    return -0.5 * tf.reduce_sum(\n",
    "        1 + tf.log(tf.square(sigma)) - tf.square(mu) - tf.square(sigma), 1)\n",
    "\n",
    "\n",
    "def flatten(inputs):\n",
    "    \"\"\"\n",
    "    Flattens a tensor along all non-batch dimensions.\n",
    "    This is correctly a NOP if the input is already flat.\n",
    "    \"\"\"\n",
    "    if len(np.shape(inputs)) == 2:\n",
    "        return inputs\n",
    "    else:\n",
    "        size = inputs.get_shape().as_list()[1:]\n",
    "        return [-1, size]\n",
    "\n",
    "def bernoulli_logp(new_image, orig_image): #(output, input)\n",
    "    \"\"\"Calculates log prob of sample under bernoulli distribution.\n",
    "    \n",
    "    Note: args must be in range [0,1]\n",
    "    \"\"\"\n",
    "    vae_loss_likelihood = tf.reduce_sum(orig_image * tf.log(EPS + new_image) +\n",
    "                         ((1 - orig_image) * tf.log(EPS + 1 - new_image)), 1)\n",
    "    return vae_loss_likelihood\n",
    "\n",
    "def discretized_logistic_logp(mean, logscale, sample, binsize=1 / 256.0):\n",
    "    \"\"\"Calculates log prob of sample under discretized logistic distribution.\"\"\"\n",
    "    scale = tf.exp(logscale)\n",
    "    sample = (tf.floor(sample / binsize) * binsize - mean) / scale\n",
    "    logp = tf.log(\n",
    "        tf.sigmoid(sample + binsize / scale) - tf.sigmoid(sample) + EPS)\n",
    "\n",
    "    if logp.shape.ndims == 4:\n",
    "        logp = tf.reduce_sum(logp, [1, 2, 3])\n",
    "    elif logp.shape.ndims == 2:\n",
    "        logp = tf.reduce_sum(logp, 1)\n",
    "    return logp\n",
    "\n",
    "def vae_loss(inputs, outputs, latent_mean, latent_log_scale, output_dist, output_log_scale=None):\n",
    "    \"\"\"Calculate the VAE loss (aka [ELBO](https://arxiv.org/abs/1312.6114))\n",
    "    \n",
    "    Args:\n",
    "        - inputs: VAE input\n",
    "        - outputs: VAE output\n",
    "        - latent_mean: parameter of latent distribution\n",
    "        - latent_log_scale: log of std. dev. of the latent distribution\n",
    "        - output_dist: distribution parameterized by VAE output, must be in ['logistic', 'bernoulli']\n",
    "        - output_log_scale: log scale parameter of the output dist if it's logistic, can be learnable\n",
    "        \n",
    "    Note: output_log_scale must be specified if output_dist is logistic\n",
    "    \"\"\"\n",
    "    # Calculate reconstruction loss\n",
    "    # Equal to minus the log likelihood of the input data under the VAE's output distribution\n",
    "    if output_dist == 'bernoulli':\n",
    "        outputs = tf.sigmoid(outputs)\n",
    "        reconstruction_loss = -bernoulli_logp(outputs, inputs)\n",
    "    elif output_dist == 'logistic':\n",
    "        outputs = tf.clip_by_value(outputs, 1 / 512., 1 - 1 / 512.)\n",
    "        reconstruction_loss = -discretized_logistic_logp(outputs, output_log_scale, inputs)\n",
    "    else:\n",
    "        print('Must specify an argument for output_dist in [bernoulli, logistic]')\n",
    "    reconstruction_loss = tf.reduce_mean(reconstruction_loss)\n",
    "        \n",
    "    # Calculate latent loss\n",
    "    latent_loss = std_gaussian_KL_divergence(latent_mean, latent_log_scale)\n",
    "    latent_loss = tf.reduce_mean(latent_loss)\n",
    "    \n",
    "    return reconstruction_loss, latent_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's specify the VAE using the logistic output distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# Specifying VAE #\n",
    "##################\n",
    "# This will go to main.py \n",
    "\n",
    "latent_size = 100\n",
    "img_shape = [32, 32, 3]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, shape=[None] + img_shape, name='input')\n",
    "\n",
    "# VAE\n",
    "with tf.name_scope('encoder') as scope:\n",
    "    means, log_scales = gaussian_encoder(inputs, latent_size)  # (?, 4, 4, 8)\n",
    "with tf.name_scope('codes') as scope:\n",
    "    codes = gaussian_sample(means, log_scales)                 # (?, 4, 4, 8)\n",
    "with tf.name_scope('decoder') as scope:\n",
    "    outputs = decoder(codes, name='output')\n",
    "\n",
    "# calculate loss with learnable parameter for output log_scale\n",
    "with tf.name_scope('loss') as scope:\n",
    "    output_log_scale = tf.get_variable(\"output_log_scale\", initializer=tf.constant(0.0, shape=img_shape))\n",
    "    reconstruction_loss, latent_loss = vae_loss(inputs, outputs, means, log_scales, 'bernoulli', output_log_scale)\n",
    "    total_loss = reconstruction_loss + latent_loss\n",
    "    #tf.summary.scalar('total_loss', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[0] = train_data_1_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th epoch...\n",
      "0 th training batch...\n",
      "gen_loss:  22.2767  lat_loss:  26.2616\n",
      "gen_loss:  22.0099  lat_loss:  5.40014\n",
      "1 th training batch...\n",
      "gen_loss:  21.7828  lat_loss:  3.3429\n",
      "gen_loss:  21.5325  lat_loss:  2.30655\n",
      "2 th training batch...\n",
      "gen_loss:  21.2333  lat_loss:  1.91002\n",
      "gen_loss:  20.8847  lat_loss:  1.54993\n",
      "3 th training batch...\n",
      "gen_loss:  20.4262  lat_loss:  1.28714\n",
      "gen_loss:  19.8431  lat_loss:  1.13225\n",
      "4 th training batch...\n",
      "gen_loss:  19.0793  lat_loss:  1.04468\n",
      "gen_loss:  17.8548  lat_loss:  1.10994\n",
      "1 th epoch...\n",
      "0 th training batch...\n",
      "gen_loss:  16.2321  lat_loss:  1.35833\n",
      "gen_loss:  14.7817  lat_loss:  1.46336\n",
      "1 th training batch...\n",
      "gen_loss:  13.8662  lat_loss:  1.50182\n",
      "gen_loss:  13.1964  lat_loss:  1.43337\n",
      "2 th training batch...\n",
      "gen_loss:  12.5341  lat_loss:  1.48698\n",
      "gen_loss:  12.1702  lat_loss:  1.52094\n",
      "3 th training batch...\n",
      "gen_loss:  11.8681  lat_loss:  1.36737\n",
      "gen_loss:  11.6251  lat_loss:  1.35985\n",
      "4 th training batch...\n",
      "gen_loss:  11.3953  lat_loss:  1.21474\n",
      "gen_loss:  11.3222  lat_loss:  1.16994\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Training VAE #\n",
    "################\n",
    "# This will go to main.py \n",
    "\n",
    "# setup optimizer\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(total_loss)\n",
    "\n",
    "# train for an epoch and visualize\n",
    "batch_size = 500\n",
    "session = tf.Session()\n",
    "#tf.summary.scalar('latent_loss', latent_loss)\n",
    "#merged = tf.summary.merge_all()\n",
    "#train_writer = tf.summary.FileWriter('logs',session.graph)\n",
    "session.run(tf.global_variables_initializer())\n",
    "for epoch in range(2):\n",
    "    print(epoch, \"th epoch...\")\n",
    "    for k in range(5):\n",
    "        print(k,\"th training batch...\")\n",
    "        for i in range(train_data[k].shape[0] // batch_size):\n",
    "            batch_xs = train_data[k][i*batch_size:(i+1)*batch_size, :]\n",
    "            #summary,_ = session.run([merged, train_op], {inputs: batch_xs})\n",
    "            _, gen_loss, lat_loss = session.run([train_op, reconstruction_loss, latent_loss], {inputs: batch_xs})\n",
    "            if i%10==0:\n",
    "                #print (\"Reconstruction Loss: \" , rl, ', Latent Loss: ', latent_loss)\n",
    "                print (\"gen_loss: \" , np.average(gen_loss), \" lat_loss: \", np.average(lat_loss))\n",
    "            #session.run(train_op, {inputs: batch_xs})\n",
    "            #train_writer.add_summary(summary, i)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.imshow(test_data[idx].astype(\"uint8\"))\n",
    "#my_test_data = np.expand_dims(test_data[idx], axis=0)\n",
    "#my_test_data\n",
    "inputs_data = np.repeat(np.expand_dims(test_data[2], axis=0), 3, axis=0)\n",
    "inputs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fee4ff37a58>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7fee6f828268> (for post_execute):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Floating point image RGB values must be in the 0..1 range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoolbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mtoolbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWAIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoolbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1295\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 548\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    772\u001b[0m         return self._make_image(\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             unsampled=unsampled)\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# (of int or float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# or an RGBA array of re-sampled input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;31m# output is now a correctly sized RGBA array of uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/cm.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(self, x, alpha, bytes, norm)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                         raise ValueError(\"Floating point image RGB values \"\n\u001b[0m\u001b[1;32m    258\u001b[0m                                          \"must be in the 0..1 range.\")\n\u001b[1;32m    259\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Floating point image RGB values must be in the 0..1 range."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Floating point image RGB values must be in the 0..1 range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2206\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2209\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoolbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mtoolbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWAIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoolbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1295\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 548\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    772\u001b[0m         return self._make_image(\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             unsampled=unsampled)\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# (of int or float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# or an RGBA array of re-sampled input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;31m# output is now a correctly sized RGBA array of uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/util/opt/anaconda/4.3.14/envs/tensorflow-1.4.0-py36/lib/python3.6/site-packages/matplotlib/cm.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(self, x, alpha, bytes, norm)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                         raise ValueError(\"Floating point image RGB values \"\n\u001b[0m\u001b[1;32m    258\u001b[0m                                          \"must be in the 0..1 range.\")\n\u001b[1;32m    259\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Floating point image RGB values must be in the 0..1 range."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee50007390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing Result of VAE #\n",
    "#############################\n",
    "# This will go to main.py \n",
    "\n",
    "# run a test\n",
    "idx = np.random.randint(test_data.shape[0])\n",
    "my_test_data = np.expand_dims(test_data[idx], axis=0)\n",
    "#inputs_data = test_data[idx]\n",
    "#output_log_scale\n",
    "\n",
    "input_out, output_log_scale_out, output_out = session.run([inputs, output_log_scale, outputs], {inputs: my_test_data})\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(np.squeeze(input_out).astype(\"uint8\"))\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(np.squeeze(output_out).astype(\"uint8\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 1.4 (py36)",
   "language": "python",
   "name": "tensorflow-1.4.0-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
