{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Issues\n",
    "# 1. VAE is trainable, but the loss doesn't get lower enough.. Thus, the reconstruction shows poor result. I will Paul about this issue\n",
    "# ... Solution 1) Use sub-pixel upsampling.\n",
    "# ... Solution 2) This might be a problem: https://distill.pub/2016/deconv-checkerboard/\n",
    "# ... Solution 3) Training more might will help\n",
    "# ... Solution 4) Rescale output image, since it is normalized at the input stage (not sure)\n",
    "\n",
    "# Idea\n",
    "# 1. Data augmentation would be helpful in terms of feeding variety dataset.\n",
    "# 2. We might want to try a stacked autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "# these ones let us draw images in our notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.python.framework import tensor_util\n",
    "import math\n",
    "\n",
    "#imports data\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# CIFAR 100 #\n",
    "#############\n",
    "\n",
    "cifar100_test = {}\n",
    "cifar100_train = {}\n",
    "# Load the raw CIFAR-100 data.\n",
    "cifar100_test = unpickle('dataset/cifar-100-python/test')\n",
    "cifar100_train = unpickle('dataset/cifar-100-python/train')\n",
    "\n",
    "train_data = cifar100_train[b'data']\n",
    "test_data = cifar100_test[b'data']\n",
    "\n",
    "train_data = np.reshape(train_data,(50000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "test_data = np.reshape(test_data,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "# CIFAR 10 #\n",
    "############\n",
    "\n",
    "cifar10_train = {}\n",
    "cifar10_test  = {}\n",
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_1')\n",
    "train_data_1 = cifar10_train[b'data']\n",
    "train_data_1 = np.reshape(train_data_1,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_2')\n",
    "train_data_2 = cifar10_train[b'data']\n",
    "train_data_2 = np.reshape(train_data_2,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_3')\n",
    "train_data_3 = cifar10_train[b'data']\n",
    "train_data_3 = np.reshape(train_data_3,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_4')\n",
    "train_data_4 = cifar10_train[b'data']\n",
    "train_data_4 = np.reshape(train_data_4,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_train = unpickle('dataset/cifar-10-python/data_batch_5')\n",
    "train_data_5 = cifar10_train[b'data']\n",
    "train_data_5 = np.reshape(train_data_5,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "cifar10_test  = unpickle('dataset/cifar-10-python/test_batch')\n",
    "test_data  = cifar10_test[b'data']\n",
    "test_data = np.reshape(test_data,(10000, 3, 32, 32)).transpose(0,2,3,1).astype(float)\n",
    "\n",
    "train_data = []\n",
    "train_data.append(train_data_1)\n",
    "train_data.append(train_data_2)\n",
    "train_data.append(train_data_3)\n",
    "train_data.append(train_data_4)\n",
    "train_data.append(train_data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# This will go to util.py #\n",
    "###########################\n",
    "\n",
    "# Normalization: Input image should be normalized to have 0 mean and unit variation for the VAE.\n",
    "train_data_normalized = train_data\n",
    "for i in range(5):\n",
    "    for j in range(10000):\n",
    "        train_data_normalized[i][j] = train_data[i][j]-np.mean(train_data[i][j])\n",
    "        train_data_normalized[i][j] = train_data_normalized[i][j]/np.std(train_data_normalized[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_data_normalized[0][9])\n",
    "#train_data_normalized[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Simple Autoencoder #\n",
    "######################\n",
    "# This one is for playing around to figure how does AE work. It won't be our model.\n",
    "\n",
    "def upscale_block(x, f, scale=2):\n",
    "    \"\"\" conv2d_transpose \"\"\"\n",
    "    x = tf.layers.conv2d_transpose(x, f, 3, strides=(scale, scale), padding='same', activation=tf.nn.relu)\n",
    "    x = tf.nn.dropout(x, 0.5)\n",
    "    return x\n",
    "\n",
    "def downscale_block(x, f, scale=2):\n",
    "    n, h, w, c = x.get_shape().as_list()\n",
    "    conv = tf.layers.conv2d(x, f, 3, strides=1, padding='same')\n",
    "    pool = tf.layers.max_pooling2d(conv, pool_size=(2,2), strides=scale, padding='same')\n",
    "    return pool\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\" inputs must be in (0, 1) \"\"\"\n",
    "    return p * tf.log(p/q) + (1-p) * tf.log((1-p)/(1-q))\n",
    "\n",
    "def autoencoder_network(x, code_size=128):\n",
    "    encoder_16 = downscale_block(x, 8)\n",
    "    encoder_8 = downscale_block(encoder_16, 16)\n",
    "    encoder_4 = downscale_block(encoder_8, 32)\n",
    "    flatten_dim = np.prod(encoder_4.get_shape().as_list()[1:])\n",
    "    flat = tf.reshape(encoder_4, [-1, flatten_dim])\n",
    "    code = tf.layers.dense(flat, code_size, activation=tf.nn.relu)\n",
    "    hidden_decoder = tf.layers.dense(code, flatten_dim, activation=tf.nn.elu)\n",
    "    decoder_4 = tf.reshape(hidden_decoder, [-1,4,4,32])\n",
    "    decoder_8 = upscale_block(decoder_4, 16)\n",
    "    decoder_16 = upscale_block(decoder_8, 8)\n",
    "    output = upscale_block(decoder_16, 3)\n",
    "    return code, output\n",
    "\n",
    "# set hyperparameters\n",
    "sparsity_weight = 5e-3\n",
    "code_size = 100\n",
    "\n",
    "# define graph\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "code, outputs = autoencoder_network(x, code_size)\n",
    "\n",
    "# just for fun\n",
    "num_params = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])\n",
    "print('Parameters: ' + str(num_params))\n",
    "\n",
    "# calculate loss\n",
    "sparsity_loss = tf.norm(code, ord=1, axis=1)\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - x)) # MSE\n",
    "total_loss = reconstruction_loss + sparsity_weight * sparsity_loss\n",
    "\n",
    "# setup optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train_op = optimizer.minimize(total_loss)\n",
    "\n",
    "# train for an epoch and visualize\n",
    "batch_size = 100\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    # train batch (1 to 5)\n",
    "    for k in range(5):\n",
    "        print(k,\"th training batch...\")\n",
    "        for i in range(train_data[k].shape[0] // batch_size):\n",
    "            batch_xs = train_data[k][i*batch_size:(i+1)*batch_size, :]\n",
    "            _,tl = session.run([train_op, total_loss], {x: batch_xs})\n",
    "            if i%10 ==0:\n",
    "                print(\"Total loss: \", np.average(tl))\n",
    "print(\"Done!\")\n",
    "#### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Simple Autoencoder #\n",
    "######################\n",
    "# Visualize result\n",
    "\n",
    "idx = np.random.randint(test_data.shape[0])\n",
    "x_out, code_out, output_out = session.run([x, code, outputs], {x: np.expand_dims(test_data[idx], axis=0)})\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(np.squeeze(x_out).astype(\"uint8\"))\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(np.squeeze(output_out).astype(\"uint8\"))\n",
    "\n",
    "#print(code_out)\n",
    "print(\"Number of nonzero code dimensions: {}/{}\".format(np.count_nonzero(code_out), code_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# model of VAE #\n",
    "################\n",
    "# This will go to model.py \n",
    "\n",
    "def lrelu(x, alpha=0.3):\n",
    "    return tf.maximum(x, tf.multiply(x, alpha))\n",
    "\n",
    "def conv_block(inputs, filters, downscale=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - inputs: 4D tensor of shape NHWC\n",
    "        - filters: int\n",
    "    \"\"\"\n",
    "    with tf.name_scope('conv_block') as scope:\n",
    "        conv = tf.layers.conv2d(inputs, filters, 2, 1, padding='same', activation=tf.nn.elu)\n",
    "        pool = tf.layers.max_pooling2d(conv, pool_size=(2,2), strides=downscale, padding='same')\n",
    "        return pool\n",
    "\n",
    "def gaussian_encoder(inputs, latent_size):\n",
    "    \"\"\"inputs should be a tensor of images whose height and width are multiples of 4\"\"\"\n",
    "    with tf.name_scope('downscale_1') as scope:\n",
    "        conv_16 = conv_block(inputs, 4, downscale=2)      # (?, 16, 16,  4)\n",
    "    with tf.name_scope('downscale_2') as scope:\n",
    "        conv_8 = conv_block(conv_16, 8, downscale=2)      # (?,  8,  8,  8)\n",
    "    with tf.name_scope('downscale_3') as scope:\n",
    "        conv_4 = conv_block(conv_8, 16, downscale=2)      # (?,  4,  4, 16)\n",
    "    conv_4_flat = tf.reshape(conv_4, [-1, 4*4*16])\n",
    "    \n",
    "    mean = tf.layers.dense(conv_4_flat, latent_size, name='mean')              # (?, 4*4*16)\n",
    "    log_scale = tf.layers.dense(conv_4_flat, latent_size, name='log_scale')    # (?, 4*4*16)\n",
    "    return mean, log_scale                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# model of VAE #\n",
    "################\n",
    "# This will go to model.py \n",
    "\n",
    "def upscale_block(x, f=1, scale=2, name='upscale_block'):\n",
    "    x = tf.layers.conv2d_transpose(x, f, 2, strides=(scale, scale), padding='same', activation=tf.nn.elu)\n",
    "    return x\n",
    "\n",
    "def decoder(codes, name):\n",
    "    hidden_decoder = tf.layers.dense(codes, 4*4*16) # (?,  4x4x8)\n",
    "#    hidden_decoder = tf.layers.dense(codes, 4*4*8) # (?,  4x4x8)\n",
    "    decoder_4 = tf.reshape(hidden_decoder, [-1, 4, 4, 16])           # (?,  4,  4, 16)\n",
    "    decoder_8 = upscale_block(decoder_4, 8, name='up_1')             # (?,  8,  8,  8)\n",
    "    decoder_16 = upscale_block(decoder_8, 4, name='up_2')            # (?, 16, 16,  4)\n",
    "    output = upscale_block(decoder_16, 3, name=name)                 # (?, 32, 32,  3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.image.per_image_standardization(train_data[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Util of VAE #\n",
    "###############\n",
    "# This will go to util.py \n",
    "\n",
    "def gaussian_sample(mean, log_scale):\n",
    "    # noise inputsis zero centered and std. dev. 1\n",
    "    gaussian_noise = tf.random_normal(shape=tf.shape(mean)) # Sampling...\n",
    "    return mean + (tf.exp(log_scale) * gaussian_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.relu(tf.reshape(inputs, [60, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# Util of VAE #\n",
    "###############\n",
    "# This will go to util.py \n",
    "\n",
    "# define an epsilon\n",
    "EPS = 1e-10\n",
    "\n",
    "def std_gaussian_KL_divergence(mu, log_sigma):\n",
    "    \"\"\"Analytic KL distance between N(mu, e^log_sigma) and N(0, 1)\"\"\"\n",
    "    sigma = tf.exp(log_sigma)\n",
    "    return -0.5 * tf.reduce_sum(\n",
    "        1 + tf.log(tf.square(sigma)) - tf.square(mu) - tf.square(sigma), 1)\n",
    "\n",
    "\n",
    "def flatten(inputs):\n",
    "    \"\"\"\n",
    "    Flattens a tensor along all non-batch dimensions.\n",
    "    This is correctly a NOP if the input is already flat.\n",
    "    \"\"\"\n",
    "    if len(np.shape(inputs)) == 2:\n",
    "        return inputs\n",
    "    else:\n",
    "        size = inputs.get_shape().as_list()[1:]\n",
    "        return [-1, size]\n",
    "\n",
    "def bernoulli_logp(new_image, orig_image): #(output, input)\n",
    "    \"\"\"Calculates log prob of sample under bernoulli distribution.\n",
    "    \n",
    "    Note: args must be in range [0,1]\n",
    "    \"\"\"\n",
    "    vae_loss_likelihood = tf.reduce_sum(orig_image * tf.log(EPS + new_image) +\n",
    "                         ((1 - orig_image) * tf.log(EPS + 1 - new_image)), 1)\n",
    "    return vae_loss_likelihood\n",
    "\n",
    "def discretized_logistic_logp(mean, logscale, sample, binsize=1 / 256.0):\n",
    "    \"\"\"Calculates log prob of sample under discretized logistic distribution.\"\"\"\n",
    "    scale = tf.exp(logscale)\n",
    "    sample = (tf.floor(sample / binsize) * binsize - mean) / scale\n",
    "    logp = tf.log(\n",
    "        tf.sigmoid(sample + binsize / scale) - tf.sigmoid(sample) + EPS)\n",
    "\n",
    "    if logp.shape.ndims == 4:\n",
    "        logp = tf.reduce_sum(logp, [1, 2, 3])\n",
    "    elif logp.shape.ndims == 2:\n",
    "        logp = tf.reduce_sum(logp, 1)\n",
    "    return logp\n",
    "\n",
    "def vae_loss(inputs, outputs, latent_mean, latent_log_scale, output_dist, output_log_scale=None):\n",
    "    \"\"\"Calculate the VAE loss (aka [ELBO](https://arxiv.org/abs/1312.6114))\n",
    "    \n",
    "    Args:\n",
    "        - inputs: VAE input\n",
    "        - outputs: VAE output\n",
    "        - latent_mean: parameter of latent distribution\n",
    "        - latent_log_scale: log of std. dev. of the latent distribution\n",
    "        - output_dist: distribution parameterized by VAE output, must be in ['logistic', 'bernoulli']\n",
    "        - output_log_scale: log scale parameter of the output dist if it's logistic, can be learnable\n",
    "        \n",
    "    Note: output_log_scale must be specified if output_dist is logistic\n",
    "    \"\"\"\n",
    "    # Calculate reconstruction loss\n",
    "    # Equal to minus the log likelihood of the input data under the VAE's output distribution\n",
    "    if output_dist == 'bernoulli':\n",
    "        outputs = tf.sigmoid(outputs)\n",
    "        reconstruction_loss = -bernoulli_logp(outputs, inputs)\n",
    "    elif output_dist == 'logistic':\n",
    "        outputs = tf.clip_by_value(outputs, 1 / 512., 1 - 1 / 512.)\n",
    "        reconstruction_loss = -discretized_logistic_logp(outputs, output_log_scale, inputs)\n",
    "    else:\n",
    "        print('Must specify an argument for output_dist in [bernoulli, logistic]')\n",
    "    reconstruction_loss = tf.reduce_mean(reconstruction_loss)\n",
    "        \n",
    "    # Calculate latent loss\n",
    "    latent_loss = std_gaussian_KL_divergence(latent_mean, latent_log_scale)\n",
    "    latent_loss = tf.reduce_mean(latent_loss)\n",
    "    \n",
    "    return reconstruction_loss, latent_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's specify the VAE using the logistic output distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# Specifying VAE #\n",
    "##################\n",
    "# This will go to main.py \n",
    "\n",
    "latent_size = 100\n",
    "img_shape = [32, 32, 3]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "inputs = tf.placeholder(tf.float32, shape=[None] + img_shape, name='input')\n",
    "\n",
    "# VAE\n",
    "with tf.name_scope('encoder') as scope:\n",
    "    means, log_scales = gaussian_encoder(inputs, latent_size)  # (?, 4, 4, 8)\n",
    "with tf.name_scope('codes') as scope:\n",
    "    codes = gaussian_sample(means, log_scales)                 # (?, 4, 4, 8)\n",
    "with tf.name_scope('decoder') as scope:\n",
    "    outputs = decoder(codes, name='output')\n",
    "\n",
    "# calculate loss with learnable parameter for output log_scale\n",
    "with tf.name_scope('loss') as scope:\n",
    "    output_log_scale = tf.get_variable(\"output_log_scale\", initializer=tf.constant(0.0, shape=img_shape))\n",
    "    reconstruction_loss, latent_loss = vae_loss(inputs, outputs, means, log_scales, 'bernoulli', output_log_scale)\n",
    "    total_loss = reconstruction_loss + latent_loss\n",
    "    #tf.summary.scalar('total_loss', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[0] = train_data_1_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# Training VAE #\n",
    "################\n",
    "# This will go to main.py \n",
    "\n",
    "# setup optimizer\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(total_loss)\n",
    "\n",
    "# train for an epoch and visualize\n",
    "batch_size = 500\n",
    "session = tf.Session()\n",
    "#tf.summary.scalar('latent_loss', latent_loss)\n",
    "#merged = tf.summary.merge_all()\n",
    "#train_writer = tf.summary.FileWriter('logs',session.graph)\n",
    "session.run(tf.global_variables_initializer())\n",
    "for epoch in range(2):\n",
    "    print(epoch, \"th epoch...\")\n",
    "    for k in range(5):\n",
    "        print(k,\"th training batch...\")\n",
    "        for i in range(train_data[k].shape[0] // batch_size):\n",
    "            batch_xs = train_data[k][i*batch_size:(i+1)*batch_size, :]\n",
    "            #summary,_ = session.run([merged, train_op], {inputs: batch_xs})\n",
    "            _, gen_loss, lat_loss = session.run([train_op, reconstruction_loss, latent_loss], {inputs: batch_xs})\n",
    "            if i%10==0:\n",
    "                #print (\"Reconstruction Loss: \" , rl, ', Latent Loss: ', latent_loss)\n",
    "                print (\"gen_loss: \" , np.average(gen_loss), \" lat_loss: \", np.average(lat_loss))\n",
    "            #session.run(train_op, {inputs: batch_xs})\n",
    "            #train_writer.add_summary(summary, i)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(test_data[idx].astype(\"uint8\"))\n",
    "#my_test_data = np.expand_dims(test_data[idx], axis=0)\n",
    "#my_test_data\n",
    "inputs_data = np.repeat(np.expand_dims(test_data[2], axis=0), 3, axis=0)\n",
    "inputs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Visualizing Result of VAE #\n",
    "#############################\n",
    "# This will go to main.py \n",
    "\n",
    "# run a test\n",
    "idx = np.random.randint(test_data.shape[0])\n",
    "my_test_data = np.expand_dims(test_data[idx], axis=0)\n",
    "#inputs_data = test_data[idx]\n",
    "#output_log_scale\n",
    "\n",
    "input_out, output_log_scale_out, output_out = session.run([inputs, output_log_scale, outputs], {inputs: my_test_data})\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(np.squeeze(input_out).astype(\"uint8\"))\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(np.squeeze(output_out).astype(\"uint8\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 1.4 (py36)",
   "language": "python",
   "name": "tensorflow-1.4.0-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
